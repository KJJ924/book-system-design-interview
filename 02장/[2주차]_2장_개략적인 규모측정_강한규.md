# 2장. 개략적인 규모 측정 

## 보편적으로 사용되는 성능 수치 항목들을 추정해서 계산하는 것 
### 필요한 기본기로 2의 제곱수나 응답지연(latency) 값과 가용성에 관계된 수치들의 이해가 있어야 한다
--- 

## 2의 제곱수
데이터 볼륨 단위를 계산하기 위해 사용 (양을 측정)
최소단위는 1바이트(8비트) 이다. 

아스키 문자 하나가 차지하는 메모리의 크기가 1바이트 이고 보통 많이 사용되는 UTF-8의 경우 1~4 바이트가 사용된다 

한글 또는 다국어를 고려할 때 한 단어를 4바이트 까지 고려하는 것이 좋겠다

책에서는 페타바이트 까지 나와 있는데 이는 2의 50제곱으로 약 1000조 바이트이다

대략 많이 사용되는 기가바이트는 약 10억 으로 2의 30제곱이다 

## 모든 프로그래머가 알아야 하는 응답지연 값
2010년 통상적인 컴퓨터의 연산들의 응답지연 값으로 현재 컴퓨터의 속도로 보기에는 약간 무리가 있다 
몇 가지 항목만 추려보면 
- 뮤텍스 락/언락 : 100ns 
- 주 메모리 참조 : 100ns
- Zippy로 1KB 압축 : 10us
- 1Gbps 네트워크로 2KB 전송 : 20,000ns = 10us
- 메모리에서 1MB 순차적으로 read : 500,000ns = 250us
- 디스크 탐색 : 10,000,000ns = 10ms
- 네트워크에서 1MB 순차적으로 read : 10ms
- 디스크에서 1MB 순차적으로 read : 30ms 
- 한 패킷의 캘리포니아로부터 네델란드까지의 왕복 지연시간 : 150ms 

결론은 
- 메모리는 빠르지만 디스크는 아직도 느리다 
- 디스크 탐색은 가능한 피하라
- 단순한 압축 알고리즘은 빠르다 
- 데이터를 인터넷으로 전송하기 전에 가능하면 압축하라(gzip)
- 데이터 센터는 보통 여러 지역에 분산되어 있고 센터들 간에 데이터를 주고받는데는 시간이 걸린다 

## 가용성에 관례된 수치들 

고가용성ㅇ은 시스템이 오랜시간 동안 지속적으로 중단 없이 운영될 수 있는 능력을 지칭함 
대부분의 서비스는 99% ~ 100% 사이의 값을 가진다
- 99% : 연간 장애시간 - 3.65일 
- 99.9% : 연간 장애시간 - 8.77시간 
- 99.99% : 연간 장애시간 - 52.60분
- 99.999% : 연간 장애시간 - 5.26분

# 트위터 QPS와 저장소 요구량 추정 

가정 
- 월간 능동 사용자는 3억 명이다 
- 50%의 사용자가 트위터를 매일 사용한다 
- 평균적으로 각 사용자는 매일 2건의 트윗을 올린다 
- 미디어를 포함하는 트윗은 10% 정도다 
- 데이터는 5년간 보관된다 

추정 
- 월간 능동 사용자는 3억 명이다 
- 50%의 사용자가 트위터를 매일 사용한다 
- 3억 * 50% = 1.5억 명 

--- 
- 평균적으로 각 사용자는 매일 2건의 트윗을 올린다
- QPS = 1.5억 * 2 트윗 / 24시간 / 1분(3600초) = 약 3500
- 최대 QPS = 3500 * 2 = 약 7000

--- 
미디어 저장을 위한 저장소 요구량 
- 평균 투윗 크기(avg)
- tweet_id 에 64바이트 
- 텍스트에 140바이트 
- 미디어에 1MB 
---
미디어를 포함하는 트윗은 10% 정도다 
- 1.5억 * 2(개) * 10% * 1MB = 30TB/일 
---
데이터는 5년간 보관된다 
- 30TB * 365일 * 5년 = 약 55PB 

# 팁 
개략적인 규모 추정과 관계된 면접에서 가장 중요한 것은 문제를 풀어 나가는 절차다 
올바른(논리적인?) 절차를 밟느냐가 결과를 내는 것보다 중요하다 
면접자가 보고 싶어하는 것은 문제 해결 능력이다 

1. 근사치를 사용한 계산을 할줄 알아야 한다. 즉 반올림, 올림, 내림에 대한 오차 수준을 생각해서 근사치로 계산시간을 줄인다
2. 가정은 적어 둬라 위에도 적혀 있다 
3. 단위를 붙이는 습관을 둬라 이건 꼼꼼함을 챙기는 포인트로 보인다 개발자는 꼼꼼함도 중요하다
4. QPS, TPS, 저장소량(?), 캐시 요구량, 서버 수 등 추정하는 방법을 미리 연습해 두어라 